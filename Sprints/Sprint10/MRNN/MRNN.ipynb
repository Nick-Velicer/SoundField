{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_subj = 2\n",
    "\n",
    "# num_games = [4]\n",
    "def FunctionGetSubData(n_subj, n_game): \n",
    "    n = 1\n",
    "    while n <= n_subj:\n",
    "        if n < 10: \n",
    "            emotions = \"../GAMEEMO/(S0{})/Preprocessed EEG Data/.csv format/S0{}G{}AllChannels.csv\".format(n, n, n_game)\n",
    "        else:\n",
    "            emotions = \"../GAMEEMO/(S{})/Preprocessed EEG Data/.csv format/S{}G{}AllChannels.csv\".format(n, n, n_game)\n",
    "        data = pd.read_csv(emotions)\n",
    "        data = data.drop(columns=[\"Unnamed: 14\"])\n",
    "        data[\"subject_num\"] = n\n",
    "        \n",
    "        if n == 1:\n",
    "            emo_df = data.iloc[15300:30600]\n",
    "        else:\n",
    "            # third minute of each subject's data\n",
    "            emo_df2 = data.iloc[15300:30600]\n",
    "            emo_df = pd.concat([emo_df, emo_df2], axis=0)\n",
    "        # emotions1= emotions1.reset_index(drop=True)\n",
    "        n = n+1\n",
    "    \n",
    "    # emotions[\"pred_valence\"] = 1\n",
    "    # emotions[\"pred_arousal\"] = 1\n",
    "    return (emo_df)\n",
    "    # print(emotions_funny.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FunctionGetGameData(n_subj, n_games):\n",
    "    for game in n_games:\n",
    "        # # 1 = bored (0,0); 2 = calm (1,0); 3 = horror (0,1); 4 = funny (1,1)\n",
    "        if game == 1:\n",
    "            emo_bored = FunctionGetSubData(n_subj, game)\n",
    "            emo_bored[\"pred_valence\"] = 0\n",
    "            emo_bored[\"pred_arousal\"] = 0\n",
    "        elif game == 2:\n",
    "            emo_calm = FunctionGetSubData(n_subj, game)\n",
    "            emo_calm[\"pred_valence\"] = 1\n",
    "            emo_calm[\"pred_arousal\"] = 0\n",
    "        elif game == 3:\n",
    "            emo_horror = FunctionGetSubData(n_subj, game)\n",
    "            emo_horror[\"pred_valence\"] = 0\n",
    "            emo_horror[\"pred_arousal\"] = 1\n",
    "        elif game == 4:\n",
    "            emo_funny = FunctionGetSubData(n_subj, game)\n",
    "            emo_funny[\"pred_valence\"] = 1\n",
    "            emo_funny[\"pred_arousal\"] = 1\n",
    "    emotions_all = pd.concat([emo_bored, emo_calm, emo_horror, emo_funny], axis=0)\n",
    "    return emotions_all\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           AF3       AF4       F3         F4       F7       F8      FC5  \\\n",
      "15300  -9.3930   9.40330   7.3046   6.108800 -11.4582  22.6112   7.6865   \n",
      "15301  -6.4192   7.15210  14.3379   3.934500   3.3293  13.4209  21.3253   \n",
      "15302   6.2582   0.21479   6.4875   0.083213  17.2295   4.6619   5.9458   \n",
      "15303  -8.2173 -13.89810  -8.0017 -14.021800   2.0957  -9.7179  -8.5109   \n",
      "15304 -12.6653 -21.37930 -13.9085 -27.280500  -2.2481 -14.5578  -2.9388   \n",
      "...        ...       ...      ...        ...      ...      ...      ...   \n",
      "30595  -7.6501  -4.00400   8.4080  -9.002600  23.2527   9.9594  18.3640   \n",
      "30596 -11.7706   6.11840  -1.9786   5.637600   7.7575   9.6031   7.8621   \n",
      "30597 -12.9927   7.19750  -3.3060   7.347900  -6.8079  -5.0731  -6.7096   \n",
      "30598 -10.7667   1.94500   7.9797   3.532700   7.7006   2.5823   7.7930   \n",
      "30599  -5.0595  -7.08980   3.4033  -0.776850  15.5537   1.7043   6.6023   \n",
      "\n",
      "            FC6       O1       O2       P7       P8        T7       T8  \\\n",
      "15300   0.34389  10.3142   5.3013  12.6977   5.7506   3.90800  -1.0627   \n",
      "15301 -13.77670   7.4056  -9.1168  -2.1642  11.4313 -10.42650   4.0625   \n",
      "15302   1.14990   1.8998   5.5302  12.0657  12.9144   4.29910  -0.2788   \n",
      "15303  15.18090 -12.3142  19.2984  25.4417  -1.9605   1.99250 -14.3621   \n",
      "15304   7.76230  -6.3933  27.0583  38.0152   5.7496   4.28290  -8.8002   \n",
      "...         ...      ...      ...      ...      ...       ...      ...   \n",
      "30595  -3.64870  -9.6651  -2.3732 -21.1420  -5.9249  -1.51780  -6.1310   \n",
      "30596   8.50110 -13.5442   7.2899  -9.6301   8.5306  -0.10121   8.3369   \n",
      "30597   1.72440 -22.3727  20.9525   2.5168  13.0803 -11.18220  -3.1300   \n",
      "30598 -12.47910  -6.9303   5.5954 -11.7342  -1.8045  -1.35240 -16.9216   \n",
      "30599 -25.83030   7.5855  -8.8404 -25.1302 -15.7962   0.89791  -2.6499   \n",
      "\n",
      "       subject_num  pred_valence  pred_arousal  \n",
      "15300            1             0             0  \n",
      "15301            1             0             0  \n",
      "15302            1             0             0  \n",
      "15303            1             0             0  \n",
      "15304            1             0             0  \n",
      "...            ...           ...           ...  \n",
      "30595            1             1             1  \n",
      "30596            1             1             1  \n",
      "30597            1             1             1  \n",
      "30598            1             1             1  \n",
      "30599            1             1             1  \n",
      "\n",
      "[61200 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "emo_all = FunctionGetGameData(1, [1, 2, 3, 4])\n",
    "print(emo_all)\n",
    "\n",
    "# emo_bored = FunctionGetSubData(6, 1)\n",
    "# print(emo_bored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42840, 14)\n",
      "(42840, 2)\n",
      "(18360, 14)\n",
      "(18360, 2)\n"
     ]
    }
   ],
   "source": [
    "# Separate Target Variable and Predictor Variables\n",
    "TargetVariable=['pred_valence', 'pred_arousal']\n",
    "# Predictors=['AF3', 'AF4', 'F3', 'F4']\n",
    "Predictors=['AF3', 'AF4', 'F3', 'F4', 'F7', 'F8' ,'FC5', 'FC6', 'O1', 'O2', 'P7', 'P8', 'T7', 'T8']\n",
    "X=emo_all[Predictors].values\n",
    "y=emo_all[TargetVariable].values\n",
    "\n",
    "### Sandardization of data ###\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "PredictorScaler=StandardScaler()\n",
    "TargetVarScaler=StandardScaler()\n",
    "\n",
    "# Storing the fit object for later reference\n",
    "PredictorScalerFit=PredictorScaler.fit(X)\n",
    "TargetVarScalerFit=TargetVarScaler.fit(y)\n",
    "\n",
    "# Generating the standardized values of X and y\n",
    "X=PredictorScalerFit.transform(X)\n",
    "y=TargetVarScalerFit.transform(y)\n",
    "\n",
    "# Split the data into training and testing set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Quick sanity check with the shapes of Training and testing datasets\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential, load_model\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import Sequential\n",
    "from sklearn.metrics import mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to find the best parameters for ANN\n",
    "def FunctionFindBestParams(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    # Defining the list of hyper parameters to try\n",
    "    batch_size_list=[10]\n",
    "    epoch_list  =   [10]\n",
    "    \n",
    "    import pandas as pd\n",
    "    SearchResultsData=pd.DataFrame(columns=['TrialNumber', 'Parameters', 'Accuracy'])\n",
    "    \n",
    "    # initializing the trials\n",
    "    TrialNumber=0\n",
    "    for batch_size_trial in batch_size_list:\n",
    "        for epochs_trial in epoch_list:\n",
    "            TrialNumber+=1\n",
    "            # create ANN model\n",
    "            model = Sequential()\n",
    "            # Defining the first layer of the model\n",
    "            model.add(Dense(units=10, input_dim=X_train.shape[1], kernel_initializer='normal', activation='relu'))\n",
    " \n",
    "            # applying dropout to layer\n",
    "            model.add(Dropout(0.1))\n",
    "\n",
    "            # Defining the Second layer of the model\n",
    "            model.add(Dense(units=10, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "            # Defining the third layer of the model\n",
    "            model.add(Dense(units=5, kernel_initializer='normal', activation='relu'))\n",
    " \n",
    "            # applying dropout to layer\n",
    "            model.add(Dropout(0.1))\n",
    "\n",
    "            # The output neuron is a single fully connected node \n",
    "            # Since we will be predicting a single number\n",
    "            model.add(Dense(2, kernel_initializer='normal'))\n",
    " \n",
    "            # Compiling the model\n",
    "            model.compile(loss='mean_squared_error', optimizer='adam')\n",
    " \n",
    "            # Fitting the ANN to the Training set\n",
    "            model.fit(X_train, y_train ,batch_size = batch_size_trial, epochs = epochs_trial, verbose=2)\n",
    " \n",
    "            # Mean absolute percentage error\n",
    "            MAPE = mean_absolute_percentage_error(y_test, model.predict(X_test))\n",
    "            \n",
    "            # printing the results of the current iteration\n",
    "            print(TrialNumber, 'Parameters:','batch_size:', batch_size_trial,'-', 'epochs:',epochs_trial, 'Accuracy:', 100-MAPE)\n",
    "            \n",
    "            SearchResultsData=SearchResultsData.append(pd.DataFrame(data=[[TrialNumber, str(batch_size_trial)+'-'+str(epochs_trial), 100-MAPE]],\n",
    "                                                                    columns=['TrialNumber', 'Parameters', 'Accuracy'] ))\n",
    "    return(SearchResultsData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "574/574 [==============================] - 2s 3ms/step\n",
      "1 Parameters: batch_size: 10 - epochs: 10 Accuracy: 99.167245085856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0v/f9chsbzs06z9v0zl61n4lws40000gn/T/ipykernel_99887/2130507986.py:49: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData=SearchResultsData.append(pd.DataFrame(data=[[TrialNumber, str(batch_size_trial)+'-'+str(epochs_trial), 100-MAPE]],\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/annaburns/Desktop/MLpractice/MRNN.ipynb Cell 8\u001b[0m in \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/annaburns/Desktop/MLpractice/MRNN.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Calling the function\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/annaburns/Desktop/MLpractice/MRNN.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m ResultsData, model \u001b[39m=\u001b[39mFunctionFindBestParams(X_train, y_train, X_test, y_test)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# Calling the function\n",
    "ResultsData =FunctionFindBestParams(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def functionBestModel(batch, epoch):\n",
    "    model = Sequential()\n",
    "    # Defining the first layer of the model\n",
    "    model.add(Dense(units=10, input_dim=X_train.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "    # applying dropout to layer\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    # Defining the Second layer of the model\n",
    "    model.add(Dense(units=10, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "    # Defining the third layer of the model\n",
    "    model.add(Dense(units=5, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "    # applying dropout to layer\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    # The output neuron is a single fully connected node \n",
    "    # Since we will be predicting a single number\n",
    "    model.add(Dense(2, kernel_initializer='normal'))\n",
    "\n",
    "    # Compiling the model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    # Fitting the ANN to the Training set\n",
    "    model.fit(X_train, y_train ,batch_size = batch, epochs = epoch, verbose=2)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4284/4284 - 18s - loss: 0.9087 - 18s/epoch - 4ms/step\n",
      "Epoch 2/10\n",
      "4284/4284 - 14s - loss: 0.8600 - 14s/epoch - 3ms/step\n",
      "Epoch 3/10\n",
      "4284/4284 - 8s - loss: 0.8463 - 8s/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "4284/4284 - 8s - loss: 0.8410 - 8s/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "4284/4284 - 7s - loss: 0.8358 - 7s/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "4284/4284 - 7s - loss: 0.8342 - 7s/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "4284/4284 - 12s - loss: 0.8335 - 12s/epoch - 3ms/step\n",
      "Epoch 8/10\n",
      "4284/4284 - 7s - loss: 0.8310 - 7s/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "4284/4284 - 10s - loss: 0.8264 - 10s/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "4284/4284 - 7s - loss: 0.8256 - 7s/epoch - 2ms/step\n"
     ]
    }
   ],
   "source": [
    "model = functionBestModel(10, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "574/574 [==============================] - 4s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "# Generating Predictions on testing data\n",
    "Predictions=model.predict(X_test)\n",
    " \n",
    "# Scaling the predicted Price data back to original price scale\n",
    "Predictions=TargetVarScalerFit.inverse_transform(Predictions)\n",
    " \n",
    "# Scaling the y_test Price data back to original price scale\n",
    "y_test_orig=TargetVarScalerFit.inverse_transform(y_test)\n",
    " \n",
    "# Scaling the test data back to original scale\n",
    "Test_Data=PredictorScalerFit.inverse_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AF3</th>\n",
       "      <th>AF4</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>FC5</th>\n",
       "      <th>FC6</th>\n",
       "      <th>O1</th>\n",
       "      <th>O2</th>\n",
       "      <th>P7</th>\n",
       "      <th>P8</th>\n",
       "      <th>T7</th>\n",
       "      <th>T8</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Arousal</th>\n",
       "      <th>PredictedValence</th>\n",
       "      <th>PredictedArousal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-13.6685</td>\n",
       "      <td>2.4037</td>\n",
       "      <td>0.51566</td>\n",
       "      <td>6.3653</td>\n",
       "      <td>6.1908</td>\n",
       "      <td>-9.4808</td>\n",
       "      <td>6.13390</td>\n",
       "      <td>6.9684</td>\n",
       "      <td>-1.0656</td>\n",
       "      <td>-2.8258</td>\n",
       "      <td>-3.6370</td>\n",
       "      <td>-8.2337</td>\n",
       "      <td>5.3518</td>\n",
       "      <td>-19.2642</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.560713</td>\n",
       "      <td>0.764184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-8.3297</td>\n",
       "      <td>4.8245</td>\n",
       "      <td>-6.48240</td>\n",
       "      <td>7.6264</td>\n",
       "      <td>-11.6985</td>\n",
       "      <td>8.3160</td>\n",
       "      <td>-3.95040</td>\n",
       "      <td>-19.4175</td>\n",
       "      <td>4.0688</td>\n",
       "      <td>-17.3575</td>\n",
       "      <td>-10.7790</td>\n",
       "      <td>-3.7511</td>\n",
       "      <td>9.2850</td>\n",
       "      <td>6.7191</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.488513</td>\n",
       "      <td>0.321006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.8005</td>\n",
       "      <td>-1.3156</td>\n",
       "      <td>0.70434</td>\n",
       "      <td>-20.0760</td>\n",
       "      <td>-16.7250</td>\n",
       "      <td>-13.5455</td>\n",
       "      <td>-17.95490</td>\n",
       "      <td>7.2087</td>\n",
       "      <td>-6.1483</td>\n",
       "      <td>14.5709</td>\n",
       "      <td>9.0522</td>\n",
       "      <td>10.1700</td>\n",
       "      <td>-12.5708</td>\n",
       "      <td>-1.8002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.558705</td>\n",
       "      <td>0.777328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.4190</td>\n",
       "      <td>-20.6000</td>\n",
       "      <td>-21.78960</td>\n",
       "      <td>-13.2994</td>\n",
       "      <td>-22.0840</td>\n",
       "      <td>-9.0131</td>\n",
       "      <td>-10.18450</td>\n",
       "      <td>13.5013</td>\n",
       "      <td>-1.3261</td>\n",
       "      <td>8.2239</td>\n",
       "      <td>8.0685</td>\n",
       "      <td>5.4493</td>\n",
       "      <td>3.3099</td>\n",
       "      <td>-17.2251</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.386243</td>\n",
       "      <td>0.170813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-7.2066</td>\n",
       "      <td>2.6147</td>\n",
       "      <td>-4.74540</td>\n",
       "      <td>13.1577</td>\n",
       "      <td>1.6130</td>\n",
       "      <td>4.1389</td>\n",
       "      <td>-0.70903</td>\n",
       "      <td>-8.3539</td>\n",
       "      <td>-18.2423</td>\n",
       "      <td>-19.1286</td>\n",
       "      <td>-4.2966</td>\n",
       "      <td>-5.5636</td>\n",
       "      <td>-13.9850</td>\n",
       "      <td>-5.3433</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.582263</td>\n",
       "      <td>0.494960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AF3      AF4        F3       F4       F7       F8       FC5      FC6  \\\n",
       "0 -13.6685   2.4037   0.51566   6.3653   6.1908  -9.4808   6.13390   6.9684   \n",
       "1  -8.3297   4.8245  -6.48240   7.6264 -11.6985   8.3160  -3.95040 -19.4175   \n",
       "2  12.8005  -1.3156   0.70434 -20.0760 -16.7250 -13.5455 -17.95490   7.2087   \n",
       "3  -4.4190 -20.6000 -21.78960 -13.2994 -22.0840  -9.0131 -10.18450  13.5013   \n",
       "4  -7.2066   2.6147  -4.74540  13.1577   1.6130   4.1389  -0.70903  -8.3539   \n",
       "\n",
       "        O1       O2       P7       P8       T7       T8  Valence  Arousal  \\\n",
       "0  -1.0656  -2.8258  -3.6370  -8.2337   5.3518 -19.2642      1.0      1.0   \n",
       "1   4.0688 -17.3575 -10.7790  -3.7511   9.2850   6.7191      1.0      1.0   \n",
       "2  -6.1483  14.5709   9.0522  10.1700 -12.5708  -1.8002      0.0      1.0   \n",
       "3  -1.3261   8.2239   8.0685   5.4493   3.3099 -17.2251      0.0      0.0   \n",
       "4 -18.2423 -19.1286  -4.2966  -5.5636 -13.9850  -5.3433      1.0      1.0   \n",
       "\n",
       "   PredictedValence  PredictedArousal  \n",
       "0          0.560713          0.764184  \n",
       "1          0.488513          0.321006  \n",
       "2          0.558705          0.777328  \n",
       "3          0.386243          0.170813  \n",
       "4          0.582263          0.494960  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TestingData=pd.DataFrame(data=Test_Data, columns=Predictors)\n",
    "TestingData[['Valence', 'Arousal']]=y_test_orig\n",
    "TestingData[['PredictedValence', 'PredictedArousal']]=Predictions\n",
    "TestingData.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
